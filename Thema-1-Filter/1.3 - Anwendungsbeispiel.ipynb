{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anwendungsbeispiel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![audio](img/audio.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inhalt  \n",
    "- [Grundlagen von Audiosignal](#1.-Grundlagen-von-Audiosignal)  \n",
    "- [Filterung mittels FIR-Filter](#2.-Filterung-mittels-FIR-Filter)    \n",
    "- [Filterung mittels IIR-Filter](#3.-Filterung-mittels-IIR-Filter)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---- "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Zweck eines Filters besteht darin, ein Eingangssignal durch eine bestimmte Operation in ein Ausgangssignal umzuwandeln, nämlich Filterung. Es gibt zwei Möglichkeiten, einen digitalen Filter zu implementieren:  \n",
    "- Softwareprogrammierung  \n",
    "- Spezielle Hardware oder allgemeiner digitaler Signalprozessor (DSP)  \n",
    "\n",
    "Für den Filterentwurf wirken sich unterschiedliche Strukturen auf die Berechnungskomplexität, den Berechnungsfehler und die Stabilität usw. aus. Daher sollte die Filterleistung für bestimmte Anwendungen angemessen berücksichtigt werden, um die Implementierung zu vereinfachen.   \n",
    "\n",
    "In Bezug auf die Leistung umfasst die IIR-Filterübertragungsfunktion zwei Sätze einstellbarer Faktoren von Null und Pol. Die einzige Einschränkung für den Pol liegt im Einheitskreis. Daher kann eine niedrigere Ordnung verwendet werden, um eine hohe Selektivität zu erhalten, eine kleine Anzahl von Speichereinheiten wird verwendet, ein geringer Rechenaufwand und eine hohe Effizienz. Dieser hohe Wirkungsgrad geht jedoch zu Lasten der Nichtlinearität der Phase. Je besser die Selektivität ist, desto schwerwiegender ist die Nichtlinearität der Phase. Der Pol der FIR-Filterübertragungsfunktion ist am Ursprung fixiert und kann seine Leistung nur durch Ändern der Nullposition ändern. Um eine hohe Selektivität zu erreichen, muss daher eine höhere Ordnung verwendet werden. Für denselben Filterdesignindex kann die erforderliche Ordnung des FIR-Filters vielmal höher sein als die des IIR-Filters, so dass die Kosten höher und die Signalverzögerung ist auch größer.\n",
    "\n",
    "In diesem Submodul werden bestimmte Frequenzkomponenten eines Eingangssignals durch verschiedene Filter entfernt, um die Eigenschaften zu vergleichen. Genauer gesagt, wir werden Bandsperrfilter zum Entfernen mit unterschiedlichen Methoden implementieren und die Ergebnisse vergleichen. Die originalen Daten des Audiosignals (akustik.wav) finden Sie unter dem Ordner 'data'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Grundlagen von Audiosignal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 Ablesen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um Audiodateien zu bearbeiten, müssen wir sie zuerst ablesen. Es gibt mehrere Methoden:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "'''\n",
    "Beispiel: Ablesen Audiodatei durch verschiedene Methoden\n",
    "'''\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "\n",
    "path = 'data/akustik.wav'\n",
    "\n",
    "# 1. wavfile:\n",
    "sr, audio = wavfile.read(path)\n",
    "\n",
    "# 2. wave:\n",
    "wavefile = wave.open(path,'rb')\n",
    "audio = wf.readframes(1024)\n",
    "\n",
    "# 3. librosa:\n",
    "audio, sr = librosa.load(path)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier benutzen wir einfach die erste Methode:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Beispiel: Audiodatei Ablesen und Visualisieren\n",
    "'''\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import fftpack\n",
    "from scipy.io import wavfile\n",
    "\n",
    "# Datei ablesen \n",
    "sr, audio = wavfile.read('data/akustik.wav')  # Sample Rate, Audiosignal im Array-Form\n",
    "audio = audio/np.max(np.abs(audio))   # Normalisierung\n",
    "\n",
    "# Initiale Daten\n",
    "fs_Hz = sr  # Abtrastfrequenz\n",
    "L = len(audio)  # Länge des Audiosignals\n",
    "T = L/fs_Hz - 1/fs_Hz  # Zeit\n",
    "t = np.linspace(0, T, L)  # Zeitbereich\n",
    "f_Hz = np.linspace(0, fs_Hz/2, int(L/2))  # Frequenzbereich\n",
    "\n",
    "# Spectrale\n",
    "audio_fft = fftpack.fft(audio)\n",
    "\n",
    "# plot\n",
    "plt.subplot(121)\n",
    "plt.title('Audiosignal im Zeitbereich')\n",
    "plt.xlabel('Zeit [s]') \n",
    "plt.ylabel('Amplitude') \n",
    "plt.plot(t, audio)\n",
    "plt.subplot(122)\n",
    "plt.title('Audiosignal im Frequenzbereich')\n",
    "plt.xlabel('Frequenz [rad]') \n",
    "plt.ylabel('Amplitude') \n",
    "plt.ylim(0, 200)\n",
    "plt.plot(f_Hz, np.abs(audio_fft[:int(L/2)]))\n",
    "plt.gcf().set_size_inches(15, 5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 Abspielen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es gibt auch verschiedene Möglichkeiten, Audiosignale mit Python abzuspielen. Zur Verwendung stellen Sie sicher, dass Sie die entsprechenden Pakete mittels \"pip install\" heruntergeladen haben, z.B.:     \n",
    "```python\n",
    "pip install scipy\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [playsound](https://pypi.org/project/playsound/)   \n",
    "Das PlaySound-Modul ist ein plattformübergreifendes Modul, das Audiodateien abspielen kann. Dies hat keine Abhängigkeiten. Man kann es einfach installieren und ausführen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from playsound import playsound\n",
    "playsound('data/akustik.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [pyaudio](https://people.csail.mit.edu/hubert/pyaudio/docs/)  \n",
    " Die offizielle API zum Abspielen von Audio und Aufnahme wird bereitgestellt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "# Datei ablesen \n",
    "wf = wave.open('data/akustik.wav', 'rb')\n",
    "audio = wf.readframes(1024)\n",
    "\n",
    "# Audio Interface\n",
    "play = pyaudio.PyAudio()\n",
    "\n",
    "# Abspielen\n",
    "stream = play.open(format=play.get_format_from_width(wf.getsampwidth()),  channels=wf.getnchannels(), rate=wf.getframerate(), output=True)\n",
    "while audio != b'':\n",
    "    stream.write(audio)\n",
    "    audio = wf.readframes(1024)\n",
    "stream.stop_stream()\n",
    "stream.close()\n",
    "\n",
    "# Beenden\n",
    "play.terminate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [IPython.display](https://ipython.org/ipython-doc/dev/api/generated/IPython.display.html)  \n",
    "Um Audio in einem Jupiter-Notebook abzuspielen, können Sie sogar die Funktion IPython.display verwenden:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "ipd.Audio('data/akustik.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [simpleaudio](https://simpleaudio.readthedocs.io/en/latest/)  \n",
    "Mit simpleaudio können wir sowohl wav-Dateien als auch NumPy-Arrays abspielen, was wir demnächst benutzen können:   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Beispiel: wav-Dateien abspielen\n",
    "'''\n",
    "import simpleaudio as sa\n",
    "\n",
    "# Datei ablesen\n",
    "wave_obj = sa.WaveObject.from_wave_file('data/akustik.wav')\n",
    "\n",
    "# abspielen\n",
    "play_obj = wave_obj.play()\n",
    "play_obj.wait_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Beispiel: NumPy-Arrays (Audiosignal) abspielen\n",
    "'''\n",
    "import simpleaudio as sa\n",
    "from scipy.io import wavfile\n",
    "\n",
    "# Datei ablesen \n",
    "sr, audio = wavfile.read('data/akustik.wav')\n",
    "\n",
    "# abspielen\n",
    "play_obj = sa.play_buffer(audio, 1, 2, sr)\n",
    "play_obj.wait_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Beispiel: NumPy-Arrays (Sinussignal) abspielen\n",
    "'''\n",
    "import numpy as np\n",
    "import simpleaudio as sa\n",
    "\n",
    "# Sinussignal erstellen\n",
    "t = np.linspace(0, 3, 8000)\n",
    "sine = np.sin(440 * np.pi * t)\n",
    "\n",
    "# Werte im 16-Bit-Bereich beschränken\n",
    "sound = sine * (2**15 - 1) / np.max(np.abs(sine))\n",
    "# in 16-Bit-Daten konvertieren\n",
    "sound = sound.astype(np.int16)\n",
    "\n",
    "# abspielen\n",
    "play_obj = sa.play_buffer(sound, 1, 2, 8000)\n",
    "play_obj.wait_done()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3 Signal addieren"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zuerst addieren wir ein solches Sinussignal ins Audiosignal zur weiteren Verarbeitung:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Beispiel: Signal addieren, visualisieren und abspielen\n",
    "'''\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import simpleaudio as sa\n",
    "from scipy import fftpack\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "\n",
    "# Datei ablesen (originales Audiosignal)\n",
    "sr, audio = wavfile.read('data/akustik.wav')\n",
    "audio = audio/np.max(np.abs(audio)) \n",
    "\n",
    "# Initiale Daten\n",
    "fs_Hz = sr  # Abtrastfrequenz\n",
    "fsin_Hz = 440  # Sinusfrequenz\n",
    "L = len(audio)  # Länge des Audiosignals\n",
    "T = L/fs_Hz - 1/fs_Hz  # Zeitraum\n",
    "t = np.linspace(0, T, L)  # Zeitbereich\n",
    "f_Hz = np.linspace(0, fs_Hz/2, int(L/2))  # Frequenzbereich\n",
    "\n",
    "# Sinussignale erstellen\n",
    "sine = 1/2 * np.sin(fsin_Hz * 2*np.pi * t)\n",
    "sine_fft = fftpack.fft(sine)\n",
    "\n",
    "# Signal zur Filterung\n",
    "s = audio + sine  # Additives Signal\n",
    "S = fftpack.fft(s)  # Frequenzgang\n",
    "\n",
    "# Fensterung (optional)\n",
    "wd = signal.get_window('hanning', L)\n",
    "s_windowed = s * wd\n",
    "\n",
    "# plot\n",
    "plt.subplot(221)\n",
    "plt.title('Rauschsignale im Zeitbereich')\n",
    "plt.xlabel('Zeit [s]') \n",
    "plt.xlim(0, 0.1)\n",
    "plt.ylabel('Amplitude') \n",
    "plt.ylim(-1, 1)\n",
    "plt.plot(t, sine)\n",
    "plt.subplot(222)\n",
    "plt.title('Rauschsignale im Frequenzbereich')\n",
    "plt.xlabel('Frequenz [rad]') \n",
    "plt.ylabel('Amplitude') \n",
    "plt.ylim(0, 500)\n",
    "plt.plot(f_Hz, np.abs(sine_fft[:int(L/2)]))\n",
    "plt.subplot(223)\n",
    "plt.title('Audiosignal mit Sinussignal im Zeitbereich')\n",
    "plt.xlabel('Zeit [s]') \n",
    "plt.ylabel('Amplitude') \n",
    "plt.plot(t, s)\n",
    "plt.subplot(224)\n",
    "plt.title('Audiosignal mit Sinussignal im Frequenzbereich')\n",
    "plt.xlabel('Frequenz [rad]') \n",
    "plt.ylabel('Amplitude') \n",
    "plt.ylim(0, 500)\n",
    "plt.plot(f_Hz, np.abs(S[:int(L/2)]))\n",
    "plt.gcf().set_size_inches(15, 10)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Abspielen\n",
    "sound = (s * (2**15 - 1) / np.max(np.abs(s))).astype(np.int16)\n",
    "play_obj = sa.play_buffer(sound, 1, 2, fs_Hz)\n",
    "play_obj.wait_done()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Filterung mittels FIR-Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 FIR-Filter mittels IDFT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jetzt entwerfen wir einen Bandsperrfilter mittels IDFT, um das Sinussignal von Audiosignal zu entfernen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Beispiel: Entfernen von Signalen mittels selbst definierten FIR-Bandsperrfilters \n",
    "'''\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import simpleaudio as sa\n",
    "from scipy import fftpack\n",
    "from scipy import signal\n",
    "\n",
    "# Filter\n",
    "bw = 30  # Bandbreite\n",
    "H = np.where((f_Hz < (fsin_Hz+bw)) & (f_Hz > (fsin_Hz-bw)), 0, 1)  \n",
    "h = np.fft.ifftshift(fftpack.ifft(H, L))   \n",
    "\n",
    "# Filterung\n",
    "s_filtered = signal.convolve(s_windowed, h, 'same')  # Faltung\n",
    "S_filtered = fftpack.fft(s_filtered)\n",
    "\n",
    "# Plot\n",
    "plt.subplot(221)\n",
    "plt.title('Impulsantwort des Filters')\n",
    "plt.xlabel('Zeit [s]') \n",
    "plt.ylabel('Amplitude') \n",
    "plt.plot(t, np.real(h))\n",
    "plt.subplot(222)\n",
    "plt.title('Spectrale des Bandsperrfilters')\n",
    "plt.xlabel('Frequenz [rad]') \n",
    "#plt.xlim(0, 1000)\n",
    "plt.ylabel('Amplitude') \n",
    "plt.plot(f_Hz, H)\n",
    "plt.subplot(223)\n",
    "plt.title('Audiosignal nach Bandsperrfilterung')\n",
    "plt.xlabel('Zeit [s]') \n",
    "plt.ylabel('Amplitude') \n",
    "plt.plot(t, np.real(s_filtered))\n",
    "plt.subplot(224)\n",
    "plt.title('Frequenzgang nach Filterung')\n",
    "plt.xlabel('Frequenz [rad]') \n",
    "plt.ylabel('Amplitude') \n",
    "plt.ylim(0, 200)\n",
    "plt.plot(f_Hz, np.abs(S_filtered[:int(L/2)]))\n",
    "plt.gcf().set_size_inches(15, 10)\n",
    "plt.show()\n",
    "\n",
    "# Abspielen\n",
    "sound = (np.real(s_filtered) * (2**15 - 1) / np.max(np.abs(s_filtered))).astype(np.int16)\n",
    "play_obj = sa.play_buffer(sound, 1, 2, fs_Hz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 FIR-Filter mittels __firwin()__  \n",
    "Für solche Anwendungen können wir aber auch die vorhandenen Filter wie [signal.firwin()](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.firwin.html) in __[scipy.signal](https://docs.scipy.org/doc/scipy/reference/signal.html)__ direkt benutzen. Das Ergebnis ist ähnlich:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Aufgabe: Entfernen von Signalen mittels signal.firwin() \n",
    "'''\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import simpleaudio as sa\n",
    "from scipy import fftpack\n",
    "from scipy import signal\n",
    "  \n",
    "# Parameter\n",
    "bw = 30  # Bandbreite\n",
    "n = 5001  # Ordnung\n",
    "wn = [(fsin_Hz-bw), (fsin_Hz+bw)]\n",
    "\n",
    "# Filterung mit Fenster\n",
    "h_fir = signal.firwin(n, wn, window='hamming', fs=fs_Hz)\n",
    "H_fir = fftpack.fft(h_fir, L)  # Spektral des Filters\n",
    "s_filtered = signal.convolve(s, h_fir, 'same')  # Faltung\n",
    "S_filtered = fftpack.fft(s_filtered)  # Spektral des Signals\n",
    "\n",
    "# plot\n",
    "plt.subplot(221)\n",
    "plt.title('Impulsantwort des Filters')\n",
    "plt.xlabel('Sample Nummer') \n",
    "plt.ylabel('Amplitude') \n",
    "plt.plot(h_fir)\n",
    "plt.subplot(222)\n",
    "plt.title('Spektral des Filters')\n",
    "plt.xlabel('Frequenz [rad]') \n",
    "plt.ylabel('Amplitude') \n",
    "plt.plot(f_Hz, np.abs(H_fir[:int(L/2)]))\n",
    "plt.subplot(223)\n",
    "plt.title('Audiosignal nach Bandsperrfilterung')\n",
    "plt.xlabel('Zeit [s]') \n",
    "plt.ylabel('Amplitude') \n",
    "plt.plot(t, s_filtered)\n",
    "plt.subplot(224)\n",
    "plt.title('Frequenzgang nach Filterung')\n",
    "plt.xlabel('Frequenz [rad]') \n",
    "plt.ylabel('Amplitude') \n",
    "plt.ylim(0, 200)\n",
    "plt.plot(f_Hz, np.abs(S_filtered[:int(L/2)]))\n",
    "plt.gcf().set_size_inches(15, 10)\n",
    "plt.show()\n",
    "\n",
    "# Abspielen\n",
    "sound = (s_filtered * (2**15 - 1) / np.max(np.abs(s_filtered))).astype(np.int16)\n",
    "play_obj = sa.play_buffer(sound, 1, 2, fs_Hz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vom Ergebnis können wir finden, um das Sinussignal zu entfernen, braucht man eine sehr hohe Ordnung zu verwenden, was bedeutet die große Anforderung von Speicherplatz, einen goßen Rechenaufwand und niedrige Effizienz.  \n",
    "\n",
    "Anschließend verwenden wir IIR-Filter zum Entfernen von Signalen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Filterung mittels IIR-Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Butterworth Filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Butterworth Filterentwurf mit Ordnung=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Beispiel: Entfernen von Signalen mittels IIR-Bandsperrfilters (Butterworth)\n",
    "'''\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import simpleaudio as sa\n",
    "from scipy import fftpack\n",
    "from scipy import signal\n",
    "\n",
    "# Parameter\n",
    "bw = 30  # Bandbreite\n",
    "n = 10  # Ordnung \n",
    "wn = [fsin_Hz-bw, fsin_Hz+bw]  # Frequenzbereich des Sperrbands\n",
    "\n",
    "# Filterung \n",
    "sos = signal.butter(n, wn, 'bs', analog=False, fs=fs_Hz, output='sos')\n",
    "w, H_butt = signal.sosfreqz(sos, int(L/2), fs=fs_Hz)\n",
    "s_filtered = signal.sosfilt(sos, s_windowed)\n",
    "S_filtered = fftpack.fft(s_filtered)\n",
    "\n",
    "# plot\n",
    "plt.subplot(311)\n",
    "plt.title('Frequenzgang des Butterworth Filters mit Ordnung=%d' %n)\n",
    "plt.xlabel('Frequenz [rad]') \n",
    "plt.ylabel('Amplitude') \n",
    "plt.plot(f_Hz, np.abs(H_butt[:int(L/2)]))\n",
    "plt.subplot(312)\n",
    "plt.title('Audiosignal nach Filterung')\n",
    "plt.xlabel('Zeit [s]') \n",
    "plt.ylabel('Amplitude') \n",
    "plt.plot(t, s_filtered)\n",
    "plt.subplot(313)\n",
    "plt.title('Frequenzgang nach Filterung')\n",
    "plt.xlabel('Frequenz [rad]') \n",
    "plt.ylabel('Amplitude') \n",
    "plt.ylim(0, 200)\n",
    "plt.plot(f_Hz, np.abs(S_filtered[:int(L/2)]))\n",
    "plt.gcf().set_size_inches(8, 16)\n",
    "plt.show()\n",
    "\n",
    "# Abspielen\n",
    "sound = (s_filtered * (2**15 - 1) / np.max(np.abs(s_filtered))).astype(np.int16)\n",
    "play_obj = sa.play_buffer(sound, 1, 2, fs_Hz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Butterworth Filterentwurf mit Ordnungselektion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Aufgabe: Entfernen von Signalen mittels IIR-Bandsperrfilters (Butterworth)\n",
    "'''\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import simpleaudio as sa\n",
    "from scipy import fftpack\n",
    "from scipy import signal\n",
    "\n",
    "# Ordnungselektion\n",
    "bw = 30  # Bandbreite\n",
    "n, wn = signal.buttord([fsin_Hz-bw-10, fsin_Hz+bw+10], [fsin_Hz-bw, fsin_Hz+bw], 10, 60, False, fs_Hz)\n",
    "\n",
    "# Filterung \n",
    "sos = signal.butter(n, wn, 'bs', False, 'sos', fs_Hz)\n",
    "w, H_butt = signal.sosfreqz(sos, int(L/2), fs=fs_Hz)\n",
    "s_filtered = signal.sosfilt(sos, s_windowed)\n",
    "S_filtered = fftpack.fft(s_filtered)\n",
    "\n",
    "# plot\n",
    "plt.subplot(311)\n",
    "plt.title('Frequenzgang des Butterworth Filters mit Ordnung=%d' %n)\n",
    "plt.xlabel('Frequenz [rad]') \n",
    "plt.ylabel('Amplitude') \n",
    "plt.plot(f_Hz, np.abs(H_butt[:int(L/2)]))\n",
    "plt.subplot(312)\n",
    "plt.title('Audiosignal nach Filterung')\n",
    "plt.xlabel('Zeit [s]') \n",
    "plt.ylabel('Amplitude') \n",
    "plt.plot(t, s_filtered)\n",
    "plt.subplot(313)\n",
    "plt.title('Frequenzgang nach Filterung')\n",
    "plt.xlabel('Frequenz [rad]') \n",
    "plt.ylabel('Amplitude') \n",
    "plt.ylim(0, 200)\n",
    "plt.plot(f_Hz, np.abs(S_filtered[:int(L/2)]))\n",
    "plt.gcf().set_size_inches(8, 16)\n",
    "plt.show()\n",
    "\n",
    "# Abspielen\n",
    "sound = (s_filtered * (2**15 - 1) / np.max(np.abs(s_filtered))).astype(np.int16)\n",
    "play_obj = sa.play_buffer(sound, 1, 2, fs_Hz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dadurch kann man herausfinden, dass die Ordnung von IIR-Filtern gegen FIR-Filtern deutlich niedrig ist."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Chebyshev Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Aufgabe: Entfernen von Signalen mittels IIR-Bandsperrfilters (Chebyshev II mit Ordnungselektion)\n",
    "'''\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import fftpack\n",
    "from scipy import signal\n",
    "\n",
    "# Ordnungselektion\n",
    "bw = 30  # Bandbreite\n",
    "n, wn = signal.cheb2ord([fsin_Hz-bw-10, fsin_Hz+bw+10], [fsin_Hz-bw, fsin_Hz+bw], 10, 60, False, fs_Hz)\n",
    "\n",
    "# Filterung\n",
    "sos = signal.cheby2(n, 60, wn, 'bs', False, 'sos', fs_Hz)\n",
    "w, H_cheby = signal.sosfreqz(sos, int(L/2), fs=fs_Hz)\n",
    "s_filtered = signal.sosfilt(sos, s_windowed)\n",
    "S_filtered = fftpack.fft(s_filtered)\n",
    "\n",
    "# plot\n",
    "plt.subplot(311)\n",
    "plt.title('Frequenzgang des Chebyshev-II Filters mit Ordnung=%d' %n)\n",
    "plt.xlabel('Frequenz [rad]') \n",
    "plt.ylabel('Amplitude') \n",
    "plt.plot(f_Hz, np.abs(H_cheby[:int(L/2)]))\n",
    "plt.subplot(312)\n",
    "plt.title('Audiosignal nach Filterung')\n",
    "plt.xlabel('Zeit [s]') \n",
    "plt.ylabel('Amplitude') \n",
    "plt.plot(t, s_filtered)\n",
    "plt.subplot(313)\n",
    "plt.title('Frequenzgang nach Filterung')\n",
    "plt.xlabel('Frequenz [rad]') \n",
    "plt.ylabel('Amplitude') \n",
    "plt.ylim(0, 200)\n",
    "plt.plot(f_Hz, np.abs(S_filtered[:int(L/2)]))\n",
    "plt.gcf().set_size_inches(8, 16)\n",
    "plt.show()\n",
    "\n",
    "# Abspielen\n",
    "sound = (s_filtered * (2**15 - 1) / np.max(np.abs(s_filtered))).astype(np.int16)\n",
    "play_obj = sa.play_buffer(sound, 1, 2, fs_Hz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zum Schluss können wir das verarbeitete Audiosignal wieder als wav-Datei speichern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Beispiel: Daten in eine wav-Datei schreiben\n",
    "'''\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "from playsound import playsound\n",
    "\n",
    "# Pfad einer neuen wav-Datei bestimmen\n",
    "file_path = 'data/akustik_filtered.wav'\n",
    "# Audiodaten in 16-Bit-Daten konvertieren\n",
    "data = (s_filtered * (2**15 - 1) / np.max(np.abs(s_filtered))).astype(np.int16)\n",
    "# Audiodaten schreiben\n",
    "wavfile.write(file_path, fs_Hz, data)\n",
    "\n",
    "# Testen, ob die Daten erfolgreich gespeichert wurde\n",
    "playsound('data/akustik_filtered.wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "1. Titelbild von [Encarni Mármol](https://lda-audiotech.com/en/2018/10/30/how-to-digitize-analog-audio/)  \n",
    "2. [Play sound in Python](https://pythonbasics.org/python-play-sound/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
