{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 - Linear Predictive Coding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: right; margin:5px 0px 0px 10px\" src=\"img/2-title.jpg\" width=\"400\">\n",
    "Die lineare Vorhersagecodierung (LPC) ist ein Verfahren, das hauptsächlich in der Audiosignalverarbeitung und Sprachverarbeitung verwendet wird, um die Spektralhüllkurve eines digitalen Sprachsignals in komprimierter Form unter Verwendung der Informationen eines linearen Vorhersagemodells darzustellen. Es ist eine der leistungsstärksten Sprachanalysetechniken und eine der nützlichsten Methoden zum Codieren von Sprache guter Qualität mit einer niedrigen Bitrate und liefert hochgenaue Schätzungen von Sprachparametern. LPC ist die am weitesten verbreitete Methode in der Sprachcodierung und Sprachsynthese.\n",
    "\n",
    "- Absender\n",
    "    - Erstellen eines Beschreibungsmodells  \n",
    "    - Extrahieren von charakteristischen Parametern, die sich auf das Sprachmodell aus dem Sprachsignal beziehen  \n",
    "\n",
    "- Empfangsende\n",
    "    - Bei der Sprachsynthese werden die entsprechenden Parameter durch entsprechende mathematische Modellberechnungen zur Sprachsynthese gesteuert\n",
    "\n",
    "## Inhalt  \n",
    "<table style=\"width:256px; border: 1px solid black; display: inline-block\">\n",
    "    <tr>\n",
    "        <td  style=\"text-align:right\" width=64px><img src=\"img/2-1.png\" style=\"float:left\"></td>\n",
    "        <td style=\"text-align:left\" width=256px>\n",
    "            <a style=\"color:black; font-size:12px; font-weight:bold; text-decoration:none\" href='#1'>\n",
    "                1. Grundlagen\n",
    "            </a>\n",
    "        </td>\n",
    "    </tr>  \n",
    "    <tr>\n",
    "        <td style=\"text-align:right\"><img src=\"img/2-2.png\" style=\"float:left\"></td>\n",
    "        <td style=\"text-align:left\" width=128px>\n",
    "            <a style=\"color:black; font-size:12px; font-weight:bold; text-decoration:none\" href='#2'>\n",
    "                2. Quelle-Filter\n",
    "            </a>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td style=\"text-align:right\"><img src=\"img/2-3.jpg\" style=\"float:left\"></td>\n",
    "        <td style=\"text-align:left\" width=128px>\n",
    "            <a style=\"color:black; font-size:12px; font-weight:bold; text-decoration:none\" href='#3'>\n",
    "                3. VocalTractLab\n",
    "            </a>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='1'></a>\n",
    "<div>\n",
    "    <img src=\"img/2-1.png\" style=\"float:left\">\n",
    "    <h2 style=\"position: relative; top: 6px; left: 6px\">\n",
    "        1.  Grundlagen\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LPC beginnt mit der Annahme, dass ein Sprachsignal von einem Summer am Ende einer Röhre erzeugt wird (stimmhafte Geräusche), mit gelegentlich hinzugefügten Zisch- und Knallgeräuschen (Zischlaute und plosive Geräusche). Obwohl dieses Modell anscheinend grob ist, ist es tatsächlich eine enge Annäherung an die Realität der Sprachproduktion. Die Glottis (der Raum zwischen den Stimmlippen) erzeugt das Summen, das durch seine Intensität (Lautstärke) und Frequenz (Tonhöhe) gekennzeichnet ist. Der Stimmapparat (Hals und Mund) bildet die Röhre, die durch ihre Resonanzen gekennzeichnet ist; Diese Resonanzen führen zu Formanten oder verbesserten Frequenzbändern im erzeugten Klang. Zischen und Knallen werden durch die Wirkung von Zunge, Lippen und Rachen während Zischlauten und Sprengstoffen erzeugt.\n",
    "\n",
    "LPC analysiert das Sprachsignal, indem es die Formanten schätzt, ihre Auswirkungen aus dem Sprachsignal entfernt und die Intensität und Frequenz des verbleibenden Summens schätzt. Der Vorgang des Entfernens der Formanten wird als inverse Filterung bezeichnet, und das verbleibende Signal nach der Subtraktion des gefilterten modellierten Signals wird als Rest bezeichnet.\n",
    "\n",
    "Die Zahlen, die die Intensität und Frequenz des Summens, die Formanten und das Rückstandssignal beschreiben, können gespeichert oder woanders übertragen werden. LPC synthetisiert das Sprachsignal durch Umkehren des Prozesses: Verwenden Sie die Buzz-Parameter und den Rest, um ein Quellensignal zu erstellen, verwenden Sie die Formanten, um einen Filter (der die Röhre darstellt) zu erstellen, und führen Sie die Quelle durch den Filter, was zu Sprache führt.\n",
    "\n",
    "Da Sprachsignale mit der Zeit variieren, wird dieser Prozess an kurzen Abschnitten des Sprachsignals durchgeführt, die als Frames bezeichnet werden. Im Allgemeinen ergeben 30 bis 50 Bilder pro Sekunde eine verständliche Sprache mit guter Komprimierung.\n",
    "\n",
    "Die Abtastwerte eines Signals $y(k)$, die durch lineare Filterung eines (unbekannten) Eingangssignals entstanden sind, sind nicht vollständig unabhängig voneinander. Statt dessen lässt sich jeder Abtastwert $y(k)$ aus endlich vielen vorangegangenen Abtastwerten durch folgende Prädiktorgleichung annähern:\n",
    "\\begin{equation}\n",
    "\\hat{y}(k)=\\sum_{i=1}^{N}a_{i}y(k-i)\n",
    "\\end{equation}\n",
    "Für jeden Abtastwert wird damit ein gewisser Prädiktionsfehler $e(k)$ gemacht:\n",
    "\\begin{equation}\n",
    "e(k)=y(k)-\\hat{y}(k)=y(k)-\\sum_{i=1}^{N}a_{i}y(k-i)\n",
    "\\end{equation}\n",
    "Die $a_{i}$ werden geschätzt, indem der mittlere quadratische Fehler im betrachteten Signalabschnitt minimiert wird.\n",
    "Bei der Analyse werden die Koeffizienten $a_{i}$ derart bestimmt, dass die Summe der Prädiktionsfehlerquadrate innerhalb eines endlichen Zeitfensters der Länge $L$ minimal wird. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'lazy_lpc'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f2f52cef83cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mlazy_lpc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlpc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'lazy_lpc'"
     ]
    }
   ],
   "source": [
    "from lazy_lpc import lpc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='2'></a>\n",
    "<div>\n",
    "    <img src=\"img/2-2.png\" style=\"float:left\">\n",
    "    <h2 style=\"position: relative; top: 6px; left: 6px\">\n",
    "        2. Quelle-Filter\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float:top; margin:5px 0px 0px 10px\" src=\"img/Quelle-Filter-Modell.jpg\" width=\"1000\">\n",
    "Die Sprache wird von unserem Soundsystem erzeugt, das mit einer einfachen Schallquelle und einem Kanalmodell simuliert werden kann. Die Schallquelle wird von den Stimmbändern erzeugt. Die Stimmbänder liefern Erregungssignale für den Soundtrack. Diese Erregung kann periodisch oder nicht periodisch sein. Wenn sich die Stimmbänder in einem vokalisierten Zustand befinden (Vibration), werden Stimmgeräusche (zum Beispiel Vokale) erzeugt, wenn sich die Stimmbänder in einem stillen Zustand befinden, werden stille Geräusche (zum Beispiel Konsonanten) erzeugt. Der Kanal kann als Filter betrachtet werden, der das Spektrum des Anregungssignals von den Stimmbändern umformen kann, um verschiedene Klänge zu erzeugen. LPC ist die auf diesem Modell basierende Sprachgenerierungstechnologie. In diesem Modell wird das Sprachsignal durch ein Anregungssignal durch ein zeitvariables Allpolfilter erzeugt. Der Koeffizient des Allpolfilters hängt von der Kanalform des spezifischen erzeugten Klangs ab. Das Anregungssignal ist entweder eine Impulsfolge von stimmhafter Sprache oder zufälliges Rauschen von leisem Ton. \n",
    "\n",
    "Die lineare Prädiktion (Linear Predictive Coding, LPC) ist eine Technik zur Analyse von zeitdiskreten Signalen, die durch einen Quelle-Filter-Prozess entstanden sind. Sie ermöglicht die Schätzung der Übertragungsfunktion bzw. Impulsantwort des Filters (im Sinne des Modells), ohne das Anregungssignal zu kennen. Die Schätzung erfolgt hinsichtlich eines Anregungssignals mit minimaler Energie. Sobald die Übertragungsfunktion geschätzt wurde, kann auch die Anregungsfunktion durch inverse Filterung geschätzt werden, d.h. Quelle und Filter werden voneinander getrennt. Die Übertragungsfunktion des geschätzten Filters ist die spektrale Hüllkurve.\n",
    "\n",
    "In Bezug auf Sprachsignale ermöglicht die LPC die Bestimmung\n",
    "- der Vokaltrakt-Übertragungsfunktion und damit der Lautidentität,\n",
    "- der Art und der Zeitfunktion der Anregung\n",
    "- der Grundperiode bei quasi-periodischer Anregung\n",
    "Sie findet breite Anwendung in der Spracherkennung, Sprachsynthese und Sprachkompression (Kodierung).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='3'></a>\n",
    "<div>\n",
    "    <img src=\"img/2-3.jpg\" style=\"float:left\">\n",
    "    <h2 style=\"position: relative; top: 6px; left: 6px\">\n",
    "        3. VocalTractLab\n",
    "    </h2>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "VocalTractLab steht für \"Vocal Tract Laboratory\" und ist ein interaktives multimediales Softwaretool zur Demonstration des Mechanismus der Sprachproduktion. Es soll Studenten der Phonetik und verwandter Disziplinen ein intuitives Verständnis der Sprachproduktion ermöglichen.\n",
    "\n",
    "VocalTractLab ist eine Open-Source-Software unter der GNU GPL (seit Version 2.3) und kostenlos. Weitere Informationen finden Sie unter [VocalTractLab](https://www.vocaltractlab.de/index.php?page=start)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Elektronische Musik Synthesen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "1. Titelbild von [Justin Stoltzfus](https://www.dataversity.net/voice-processing-are-we-near-new-speech-recognition-apps/#), [Emflazie](https://en.wikipedia.org/wiki/Source%E2%80%93filter_model#/media/File:Source-filter_model_diagram.svg), [adaptivedigital](https://www.adaptivedigital.com/lpc/)   \n",
    "2. [Linear predictive coding](https://en.wikipedia.org/wiki/Linear_predictive_coding)\n",
    "3. [Introduction - Linear predictive coding](http://support.ircam.fr/docs/AudioSculpt/3.0/co/LPC.html)  \n",
    "4. [VocalTractLab](https://www.vocaltractlab.de/index.php?page=start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
